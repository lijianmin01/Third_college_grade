{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Contraceptive Method\n",
    "\n",
    "\n",
    "The objective of this study is to predict the contraceptive method (no use, long-term methods,or short-term methods) of a woman based on her demographic and socio-economic characteristics.  \n",
    "\n",
    "A data-set of 1473 married women with their demographic and socio-economic characteristics is used in this study. The Source for the data-set is the UCI Machine Learning Repository at, \n",
    "http://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice <cite data-cite=\"Contraceptive_Method_Choice_UCI\">(Dua, D. and Graff, C., 2013)</cite>.\n",
    "\n",
    "This study consists with two phases. Objective of the Phase I is to preprocess and explore the data-set in order to make it ready for Phase II. The objective of phase II is to build a model that predicts the contraceptive method of a women based on here demograpic and socio-econimic characteristics.\n",
    "\n",
    "All the activities have been performed in `Python` package in this study and compiled from [Jupyter Notebook](http://jupyter.org/).\n",
    "\n",
    "This report does not cover the Phase I scope of work (Phase I report has been submitted under the previous assignment submission under this course). This report covers both narratives and the `Python` codesudes for the model building & evaluation which performed under the phase II.\n",
    "\n",
    "Content of this report is organized as follows. \n",
    "- [Section 2 (Overview)](#2) summary of the data-set and the methodology.\n",
    "- [Section 3 (Data Preparation)](#3) data preparation process and the model evaluation strategy. \n",
    "- [Section 4 (Hyperparameter Tuning)](#4) hyperparameter tuning process for each classification algorithm.\n",
    "- [Section 5 (Performance Comparison)](#5) model performance comparison results.\n",
    "- [Section 6 (Limitations)](#6) limitations of the approach and possible solutions. \n",
    "- [Section 7 (Summary)](#7) summary of the project.\n",
    "\n",
    "\n",
    "# 2. Overview <a class=\"anchor\" id=\"2\"></a> \n",
    "\n",
    "### Data-set\n",
    "\n",
    "The date-set contains contraceptive methods used & nine other demographic and socio-economic characteristics of 1473 married women in Indonesia, which obtains from National Indonesia Contraceptive Prevalence Survey in 1987. The data-set has 9 descriptive features and one target feature.\n",
    "\n",
    "\n",
    "#### Target Feature\n",
    "\n",
    "The response feature is contraceptive method which is given as:\n",
    "\n",
    "\n",
    "$$\\text{contraceptive method} = \\begin{cases}  long-term & \\text{ if the contraceptive method is long term} \\\\short-term & \\text{ if the contraceptive method is short term } \\\\ no-use & \\text{ if no contraceptive method is used }\\end{cases}$$\n",
    "\n",
    "The target feature has three classes. Hence this can be classified as multinominal (multiclass) target feature. \n",
    "\n",
    "#### Descriptive Features\n",
    "\n",
    "Following are the descriptive features in the data-set.\n",
    "\n",
    "\n",
    "* **`Wife's age`**: numerical \n",
    "* **`Wife's education`**: categorical (low, medium low, medium high, high)\n",
    "* **`Husband's education`**: categorical (low, medium low, medium high, high) \n",
    "* **`Number of children ever born`**: numerical\n",
    "* **`Wife's religion`**: binary (Non-Islam, Islam)\n",
    "* **`Wife's now working?`**: binary (Yes, No) \n",
    "* **`Husband's occupation`**: categorical (Cat1, Cat2, Cat3, Cat4) \n",
    "* **`Standard-of-living index`**: categorical (low, medium low, medium high, high)\n",
    "* **`Media exposure`**: binary (Good, Bad) \n",
    "\n",
    "All the descriptive features are self-explanatory.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "The data-set that had been preprocessed under Phase I, is now being used in this Phase of work. The data-set has been further preprocessed in order to use it in Scikit-Learn functions. Those additional preprocessed steps that are used under this Phase are,\n",
    "\n",
    "    * Checking for missing values\n",
    "    * Discretizing wife's age feature\n",
    "    * Making ordinal categorical Features using Numeric-Integer-Encoding\n",
    "    * Splitting data-set into the set of descriptive features and the target\n",
    "    * Making nominal categorical features using One-Hot-Encoding\n",
    "    * Encoding target\n",
    "    * Scaling descriptive features\n",
    "    * Feature selection & ranking using Random Forest Importance (RFI) \n",
    "    * Splitting data-set into training and test sets\n",
    "    * Selecting evaluation strategy\n",
    "\n",
    "Three different Machine-Learning (ML) classifier algorithms have been explored and built to predict the target feature. Those three ML algorithms are, \n",
    "\n",
    "    * K-Nearest Neighbors (KNN)\n",
    "    * (Gaussian) Naive Bayes (NB)\n",
    "    * Decision Trees (DT)\n",
    "\n",
    "All the observation in the data-set (i.e. full data-set) have been used in for modeling keeping 70:30 ratio of observations for training and test perspectives. This comes down to 1031 observations for training set, while 442 observations for test set. \n",
    "\n",
    "A pipeline technique is used in modeling: firstly, feature selection has been performed using Random Forest Importance method considering 3, 4, 5, ... 9 features. Secondly, the hyper-parameter tuning has been performed for each classifier and subsequently, 'accuracy' method is used to evaluate the performance. \n",
    "\n",
    "After selecting the best model, 5-fold cross-validation was performed on test data and performed a paired t-test to determine whether there is any statistically significant difference in each model pair. Additionally, the model was assessed using recall scores and confusion matrices on the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation <a class=\"anchor\" id=\"3\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data-set\n",
    "\n",
    "The data-set that had been preprocessed under Phase I has been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:30.131218Z",
     "start_time": "2020-10-07T11:41:29.452998Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the data set is (1473,10).\n",
      "\n",
      "Data Types are: \n",
      "\n",
      "wife_age           int64\n",
      "wife_edu          object\n",
      "husb_edu          object\n",
      "children           int64\n",
      "wife_religion     object\n",
      "wife-working      object\n",
      "husb-occup        object\n",
      "s-living_index    object\n",
      "media_exp         object\n",
      "contrac_mthd      object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Random rows in the Data-set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wife_age</th>\n",
       "      <th>wife_edu</th>\n",
       "      <th>husb_edu</th>\n",
       "      <th>children</th>\n",
       "      <th>wife_religion</th>\n",
       "      <th>wife-working</th>\n",
       "      <th>husb-occup</th>\n",
       "      <th>s-living_index</th>\n",
       "      <th>media_exp</th>\n",
       "      <th>contrac_mthd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>28</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cat2</td>\n",
       "      <td>high</td>\n",
       "      <td>good</td>\n",
       "      <td>Short-term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>25</td>\n",
       "      <td>middle high</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cat2</td>\n",
       "      <td>high</td>\n",
       "      <td>good</td>\n",
       "      <td>Short-term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>43</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>5</td>\n",
       "      <td>Islam</td>\n",
       "      <td>No</td>\n",
       "      <td>Cat1</td>\n",
       "      <td>high</td>\n",
       "      <td>good</td>\n",
       "      <td>Short-term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>24</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>Islam</td>\n",
       "      <td>No</td>\n",
       "      <td>Cat1</td>\n",
       "      <td>high</td>\n",
       "      <td>good</td>\n",
       "      <td>Short-term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>33</td>\n",
       "      <td>middle high</td>\n",
       "      <td>middle high</td>\n",
       "      <td>4</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cat2</td>\n",
       "      <td>middle low</td>\n",
       "      <td>good</td>\n",
       "      <td>Short-term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>39</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "      <td>Cat2</td>\n",
       "      <td>high</td>\n",
       "      <td>good</td>\n",
       "      <td>Long-term</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      wife_age     wife_edu     husb_edu  children wife_religion wife-working  \\\n",
       "1440        28         high         high         1         Other          Yes   \n",
       "1387        25  middle high         high         2         Islam          Yes   \n",
       "899         43         high         high         5         Islam           No   \n",
       "751         24         high         high         2         Islam           No   \n",
       "1471        33  middle high  middle high         4         Islam          Yes   \n",
       "1279        39         high         high         3         Other           No   \n",
       "\n",
       "     husb-occup s-living_index media_exp contrac_mthd  \n",
       "1440       Cat2           high      good   Short-term  \n",
       "1387       Cat2           high      good   Short-term  \n",
       "899        Cat1           high      good   Short-term  \n",
       "751        Cat1           high      good   Short-term  \n",
       "1471       Cat2     middle low      good   Short-term  \n",
       "1279       Cat2           high      good    Long-term  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#reading the data-set\n",
    "df_con=pd.read_csv('Preprocessed_Data.csv')\n",
    "\n",
    "#examining the dta-set\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "print(\"Dimension of the data set is ({},{}).\\n\".format(df_con.shape[0],df_con.shape[1]) )\n",
    "    \n",
    "print(\"Data Types are: \\n\")\n",
    "print(df_con.dtypes)\n",
    "printmd(\"Random rows in the Data-set\")\n",
    "df_con.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for missing values\n",
    "\n",
    "The missing values can have a significant impact to the data model. Hence it is always a good practice to check and ensure that there are no missing values before building the model. As can be seen below, there are no missing values in the processed data-set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:30.142157Z",
     "start_time": "2020-10-07T11:41:30.133211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wife_age          0\n",
       "wife_edu          0\n",
       "husb_edu          0\n",
       "children          0\n",
       "wife_religion     0\n",
       "wife-working      0\n",
       "husb-occup        0\n",
       "s-living_index    0\n",
       "media_exp         0\n",
       "contrac_mthd      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_con.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretizing Numeric Features\n",
    "\n",
    "Since this is a classification task, it is being assumed that transforming the numerical Age feature to ordinal variable will lead to a better performance in the model. As shown below, the Age feature has been transformed to ordinal variable with three levels:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:30.210970Z",
     "start_time": "2020-10-07T11:41:30.144150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "young          547\n",
       "old            469\n",
       "middle-aged    457\n",
       "Name: wife_age, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contr_df = df_con.copy()\n",
    "contr_df['wife_age'] = pd.qcut(contr_df['wife_age'], q=3, \n",
    "                                     labels=['young', 'middle-aged', 'old'])\n",
    "contr_df['wife_age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Ordinal Categorical Features Numeric (using Integer-Encoding)\n",
    "\n",
    "All descriptive attributes in the data-set (including target and descriptive features) need to be converted to numeric features, in order to use the data-set in Scikit-Learn functions. Integer-Encoding has been done for the ordinal categorical features as below. It is worth mentioning that \"wife_edu\", \"husd_edu\", \"husb-occup\", \"s-livinh_index\", and \"media_exp\" in this data-set do have natural ordering, hence consider as ordinal variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:30.248880Z",
     "start_time": "2020-10-07T11:41:30.212967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types are: \n",
      "\n",
      "wife_age           int64\n",
      "wife_edu           int64\n",
      "husb_edu           int64\n",
      "children           int64\n",
      "wife_religion     object\n",
      "wife-working      object\n",
      "husb-occup         int64\n",
      "s-living_index     int64\n",
      "media_exp          int64\n",
      "contrac_mthd      object\n",
      "dtype: object\n",
      "Random rows in the Data-set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wife_age</th>\n",
       "      <th>wife_edu</th>\n",
       "      <th>husb_edu</th>\n",
       "      <th>children</th>\n",
       "      <th>wife_religion</th>\n",
       "      <th>wife-working</th>\n",
       "      <th>husb-occup</th>\n",
       "      <th>s-living_index</th>\n",
       "      <th>media_exp</th>\n",
       "      <th>contrac_mthd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Short-term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Short-term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Islam</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No-use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Islam</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Short-term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Islam</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Short-term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Islam</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>No-use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      wife_age  wife_edu  husb_edu  children wife_religion wife-working  \\\n",
       "875          2         4         4         3         Islam          Yes   \n",
       "933          1         4         4         2         Other           No   \n",
       "100          1         1         2         4         Islam           No   \n",
       "1418         3         4         4         5         Islam           No   \n",
       "785          1         3         3         3         Islam           No   \n",
       "1006         1         4         4         0         Islam          Yes   \n",
       "\n",
       "      husb-occup  s-living_index  media_exp contrac_mthd  \n",
       "875            1               4          0   Short-term  \n",
       "933            2               4          0   Short-term  \n",
       "100            3               1          1       No-use  \n",
       "1418           3               2          0   Short-term  \n",
       "785            2               2          0   Short-term  \n",
       "1006           1               4          0       No-use  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup_nums = {\"wife_age\": {\"young\": 1, \"middle-aged\": 2, \"old\": 3},\n",
    "                \"wife_edu\": {\"low\": 1, \"middle low\": 2, \"middle high\": 3, \"high\": 4},\n",
    "                \"husb_edu\": {\"low\": 1, \"middle low\": 2, \"middle high\": 3, \"high\": 4},\n",
    "                \"husb-occup\": {\"Cat1\": 1, \"Cat2\": 2, \"Cat3\": 3, \"Cat4\": 4},\n",
    "                \"s-living_index\": {\"low\": 1, \"middle low\": 2, \"middle high\": 3, \"high\": 4},\n",
    "                \"media_exp\": {\"good\": 0, \"bad\": 1}}\n",
    "contr_df.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "#checking the data-set\n",
    "print(\"Data Types are: \\n\")\n",
    "print(contr_df.dtypes)\n",
    "print(\"Random rows in the Data-set\")\n",
    "contr_df.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data-set into the set of descriptive features and the target\n",
    "\n",
    "Before encoding the target feature, it is required to split the data-set into descriptive features and the target feature. Then the target feature has been examined to see the distribution of each label. As shown below, the target features of No-use, Short-term and Long-term have 629, 511 and 333 instances, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:30.273802Z",
     "start_time": "2020-10-07T11:41:30.250865Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No-use        629\n",
       "Short-term    511\n",
       "Long-term     333\n",
       "Name: contrac_mthd, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contr_df_cat = contr_df.copy()\n",
    "#Splitting data-set into the set of descriptive features and the target\n",
    "Data = contr_df_cat.drop(columns = 'contrac_mthd')\n",
    "target = contr_df_cat['contrac_mthd']\n",
    "\n",
    "# Checking the count of instances in each label\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Nominal Categorical Features Numeric (using One-Hot-Encoding)\n",
    "\n",
    "In the data-set, \"wife_religion\", and \"wife-working\" attributes are considered as nominal variables because they possess no natural ordering. The One-Hot-Encoding method has been used in for transforming these nominal variables to numerical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:30.298766Z",
     "start_time": "2020-10-07T11:41:30.275797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wife_religion', 'wife-working']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = Data.columns[Data.dtypes==object].tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For two-level categorical features, drop_first option has been set to 'True' to encode the variable into a single column of 0 or 1. If there are ordinal categorical features with more than two levels, *Data = pd.get_dummies(Data)* function can be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:30.308747Z",
     "start_time": "2020-10-07T11:41:30.300732Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    n = len(Data[col].unique())\n",
    "    if (n == 2):\n",
    "        Data[col] = pd.get_dummies(Data[col], drop_first=True)\n",
    "\n",
    "# use one-hot-encoding for categorical features with >2 levels\n",
    "#Data = pd.get_dummies(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:30.322697Z",
     "start_time": "2020-10-07T11:41:30.312732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wife_age</th>\n",
       "      <th>wife_edu</th>\n",
       "      <th>husb_edu</th>\n",
       "      <th>children</th>\n",
       "      <th>wife_religion</th>\n",
       "      <th>wife-working</th>\n",
       "      <th>husb-occup</th>\n",
       "      <th>s-living_index</th>\n",
       "      <th>media_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      wife_age  wife_edu  husb_edu  children  wife_religion  wife-working  \\\n",
       "656          1         3         4         2              0             0   \n",
       "1259         1         4         4         1              0             1   \n",
       "652          2         2         2         4              0             0   \n",
       "1054         1         4         4         1              0             0   \n",
       "975          2         4         4         3              0             0   \n",
       "\n",
       "      husb-occup  s-living_index  media_exp  \n",
       "656            1               3          0  \n",
       "1259           1               4          0  \n",
       "652            2               4          0  \n",
       "1054           1               4          0  \n",
       "975            3               4          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Target\n",
    "\n",
    "The target feature has been encoded to numeric values as shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:35.646967Z",
     "start_time": "2020-10-07T11:41:30.324668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([333, 629, 511], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding Target\n",
    "from sklearn import preprocessing\n",
    "target = preprocessing.LabelEncoder().fit_transform(target)\n",
    "\n",
    "#Checking the encoding\n",
    "print(type(target))\n",
    "np.unique(target, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Long-term' is labeled as 0, 'No-use' is labeled as 1 and 'Short-term' is labeled as 2 due to the fact that the LabelEncoder() function labels them in alphabetical order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Descriptive Features\n",
    "\n",
    "Feature scaling  (Standardization) is performed to get the highly varying numeric data to a common scale. Even though the scaling is essential only for some of the models (such as KNN, Deep learning and SVMs), scaling is highly recommended for any model. Therefore, Min-Max Scaling has been used in this task, which can convert numerical data to common scale between 0 and 1.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:35.657936Z",
     "start_time": "2020-10-07T11:41:35.649959Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#Data_df = Data.copy()\n",
    "\n",
    "Data_scaler = preprocessing.MinMaxScaler()\n",
    "Data_scaler.fit(Data)\n",
    "Data = Data_scaler.fit_transform(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection & Ranking\n",
    "\n",
    "In this section, best 6 features of the data-set has been examined using Random Forest Importance (RFI) to get an quick understanding on the importance of each feature. However, during the hyperparameter tuning phase inside the pipeline, the feature selection is performed in more systematic and detailed way using RFI, which eventually determines the optimal number of features for each classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the best 6 features in the dataset using RFI (Random Forest Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:51:01.859950Z",
     "start_time": "2020-10-07T11:51:01.702357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['children', 's-living_index', 'wife_edu', 'husb-occup', 'wife_age',\n",
       "       'husb_edu', 'wife-working', 'wife_religion', 'media_exp'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "num_features = 9\n",
    "model_rfi = RandomForestClassifier(n_estimators=100)\n",
    "model_rfi.fit(Data, target)\n",
    "fs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]\n",
    "\n",
    "best_features_rfi = contr_df_cat.columns[fs_indices_rfi].values\n",
    "best_features_rfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:51:04.451404Z",
     "start_time": "2020-10-07T11:51:04.437471Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32819568, 0.12782804, 0.11391385, 0.11229324, 0.10034922,\n",
       "       0.0935373 , 0.05910047, 0.04005737, 0.02472484])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_rfi = model_rfi.feature_importances_[fs_indices_rfi]\n",
    "feature_importances_rfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:37.432478Z",
     "start_time": "2020-10-07T11:41:36.719124Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const spec = {\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-bcbdfecc2bdb986a0f281d4fbd9fd457\"}, \"mark\": {\"type\": \"bar\", \"color\": \"blue\", \"opacity\": 0.85}, \"encoding\": {\"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 45}, \"field\": \"features\", \"sort\": null, \"title\": \"Feature\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"importances\", \"title\": \"Importance\"}}, \"title\": \"Random Forest Feature Importances\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-bcbdfecc2bdb986a0f281d4fbd9fd457\": [{\"features\": \"children\", \"importances\": 0.3262231750726696}, {\"features\": \"s-living_index\", \"importances\": 0.12810159626049372}, {\"features\": \"wife_edu\", \"importances\": 0.11640532239526698}, {\"features\": \"husb-occup\", \"importances\": 0.11064925093367384}, {\"features\": \"wife_age\", \"importances\": 0.09979799698732111}, {\"features\": \"husb_edu\", \"importances\": 0.09552830739931721}]}};\n",
       "const opt = {};\n",
       "const type = \"vega-lite\";\n",
       "const id = \"0ccd2f40-7238-447c-bbad-0519e64b40d6\";\n",
       "\n",
       "const output_area = this;\n",
       "\n",
       "require([\"nbextensions/jupyter-vega/index\"], function(vega) {\n",
       "  const target = document.createElement(\"div\");\n",
       "  target.id = id;\n",
       "  target.className = \"vega-embed\";\n",
       "\n",
       "  const style = document.createElement(\"style\");\n",
       "  style.textContent = [\n",
       "    \".vega-embed .error p {\",\n",
       "    \"  color: firebrick;\",\n",
       "    \"  font-size: 14px;\",\n",
       "    \"}\",\n",
       "  ].join(\"\\\\n\");\n",
       "\n",
       "  // element is a jQuery wrapped DOM element inside the output area\n",
       "  // see http://ipython.readthedocs.io/en/stable/api/generated/\\\n",
       "  // IPython.display.html#IPython.display.Javascript.__init__\n",
       "  element[0].appendChild(target);\n",
       "  element[0].appendChild(style);\n",
       "\n",
       "  vega.render(\"#\" + id, spec, type, opt, output_area);\n",
       "}, function (err) {\n",
       "  if (err.requireType !== \"scripterror\") {\n",
       "    throw(err);\n",
       "  }\n",
       "});\n"
      ],
      "text/plain": [
       "<vega.vegalite.VegaLite at 0x12295a2fbc8>"
      ]
     },
     "metadata": {
      "jupyter-vega": "#0ccd2f40-7238-447c-bbad-0519e64b40d6"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "alt.renderers.enable('notebook')\n",
    "\n",
    "def plot_imp(best_features, scores, method_name, color):\n",
    "    \n",
    "    df = pd.DataFrame({'features': best_features, \n",
    "                       'importances': scores})\n",
    "    \n",
    "    chart = alt.Chart(df, \n",
    "                      width=500, \n",
    "                      title=method_name + ' Feature Importances'\n",
    "                     ).mark_bar(opacity=0.85, \n",
    "                                color=color).encode(\n",
    "        alt.X('features', title='Feature', sort=None, axis=alt.AxisConfig(labelAngle=45)),\n",
    "        alt.Y('importances', title='Importance')\n",
    "    )\n",
    "    \n",
    "    return chart\n",
    "\n",
    "#plotting\n",
    "plot_imp(best_features_rfi, feature_importances_rfi, 'Random Forest', 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the results above, best 6 features of the data-set are 'children', 's-living_index', 'wife_edu', 'husb-occup',  'wife_age', and 'husb_edu'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Test Sets\n",
    "\n",
    "Data sampling is not required as the original data-set is not a significantly larger one: data-set only has 1473 observations.\n",
    "As shown below, the model has been trained and tuned on 1031 rows of training data and tested on 442 rows of test data. This is constituted from 70:30 ratio of training Vs test observations in the data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:37.442452Z",
     "start_time": "2020-10-07T11:41:37.434473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1031, 9)\n",
      "(442, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "D_train, D_test, t_train, t_test = \\\n",
    "    train_test_split(Data, target, test_size = 0.3, \n",
    "                     stratify=target, shuffle=True, random_state=999)\n",
    "\n",
    "print(D_train.shape)\n",
    "print(D_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Strategy\n",
    "\n",
    "Stratified 5-fold cross-validation with 3 repetitions has been used as the model evaluation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:37.450430Z",
     "start_time": "2020-10-07T11:41:37.445442Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5,\n",
    "                                    n_repeats=3,\n",
    "                                    random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter Tuning <a class=\"anchor\" id=\"4\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a pipeline can be used to automate the work-flows of the machine learning, it has been used in for feature selection and hyperparameter tuning. The grid search for hyperparameter tuning of each classifiers has been performed via cross-validation approach. In addition to the hyperparameter tuning, feature selection using RFI has also been stacked to the pipeline along with the checks for best number of feature to be selected. \n",
    "\n",
    "KNN, NB & DT classifiers have been chosen for this classification task. As shown below, each classifier has been optimized using the training data for optimal parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)\n",
    "\n",
    "A dictionary for the hyperparameters of the KNN classifier is defined as below:\n",
    "\n",
    "* value range for \"number of neighbors (n_neighbors)\": 1, 10, 20, 40, 60, 100\n",
    "* values for $p$: 1 (Manhattan), 2 (Euclidean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:37.459430Z",
     "start_time": "2020-10-07T11:41:37.452423Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# custom function for RFI feature selection inside a pipeline\n",
    "class RFIFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # class constructor \n",
    "    def __init__(self, n_features_=6):\n",
    "        self.n_features_ = n_features_\n",
    "        self.fs_indices_ = None\n",
    "\n",
    "    # override the fit function\n",
    "    def fit(self, X, y):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from numpy import argsort\n",
    "        model_rfi = RandomForestClassifier(n_estimators=100)\n",
    "        model_rfi.fit(X, y)\n",
    "        self.fs_indices_ = argsort(model_rfi.feature_importances_)[::-1][0:self.n_features_] \n",
    "        return self \n",
    "    \n",
    "    # override the transform function\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.fs_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:41:37.489356Z",
     "start_time": "2020-10-07T11:41:37.461405Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pipe_KNN = Pipeline(steps=[('rfi_fs', RFIFeatureSelector()), \n",
    "                           ('knn', KNeighborsClassifier())])\n",
    "\n",
    "params_pipe_KNN = {'rfi_fs__n_features_': [3,4,5,6,7,8,9, Data.shape[1]],\n",
    "                   'knn__n_neighbors': [1, 10, 20, 40, 60, 100],\n",
    "                   'knn__p': [1, 2]}\n",
    "\n",
    "gs_pipe_KNN = GridSearchCV(estimator=pipe_KNN, \n",
    "                           param_grid=params_pipe_KNN, \n",
    "                           cv=cv_method,\n",
    "                           refit=True,\n",
    "                           n_jobs=-2,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:38.448346Z",
     "start_time": "2020-10-07T11:41:37.491322Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 96 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-2)]: Done 186 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-2)]: Done 436 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-2)]: Done 786 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-2)]: Done 1236 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-2)]: Done 1440 out of 1440 | elapsed:  1.0min finished\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gs_pipe_KNN.fit(D_train, t_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:38.456293Z",
     "start_time": "2020-10-07T11:42:38.450341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 20, 'knn__p': 2, 'rfi_fs__n_features_': 5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_KNN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:38.465270Z",
     "start_time": "2020-10-07T11:42:38.458288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5379890074361461"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_KNN.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the KNN model has a mean accuracy score of 0.535. The best parameters for the KNN model are 5 features with 20 nearest neighbors and $p=2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the KNN model accuracy based on other parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:38.477235Z",
     "start_time": "2020-10-07T11:42:38.467262Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom function to format the search results as a Pandas data frame\n",
    "\n",
    "def get_search_results(gs):\n",
    "    \n",
    "    def model_result(scores, params):\n",
    "        scores = {'mean_score': np.mean(scores),\n",
    "             'std_score': np.std(scores),\n",
    "             'min_score': np.min(scores),\n",
    "             'max_score': np.max(scores)}\n",
    "        return pd.Series({**params,**scores})\n",
    "    \n",
    "    models = []\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(gs.n_splits_):\n",
    "        key = f\"split{i}_test_score\"\n",
    "        r = gs.cv_results_[key]\n",
    "        scores.append(r.reshape(-1,1))\n",
    "        \n",
    "    all_scores = np.hstack(scores)\n",
    "    for p, s in zip(gs.cv_results_['params'], all_scores):\n",
    "        models.append((model_result(s, p)))\n",
    "\n",
    "    pipe_results = pd.concat(models, axis=1).T.sort_values(['mean_score'], ascending=False)\n",
    "\n",
    "    columns_first = ['mean_score', 'std_score', 'max_score', 'min_score']\n",
    "    columns = columns_first + [c for c in pipe_results.columns if c not in columns_first]\n",
    "\n",
    "    return pipe_results[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:38.582985Z",
     "start_time": "2020-10-07T11:42:38.480228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>knn__n_neighbors</th>\n",
       "      <th>knn__p</th>\n",
       "      <th>rfi_fs__n_features_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.538021</td>\n",
       "      <td>0.030235</td>\n",
       "      <td>0.595122</td>\n",
       "      <td>0.497561</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.536433</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>0.619512</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.533506</td>\n",
       "      <td>0.030729</td>\n",
       "      <td>0.604878</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.532265</td>\n",
       "      <td>0.032875</td>\n",
       "      <td>0.590244</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.529007</td>\n",
       "      <td>0.033383</td>\n",
       "      <td>0.590244</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_score  std_score  max_score  min_score  knn__n_neighbors  knn__p  \\\n",
       "42    0.538021   0.030235   0.595122   0.497561              20.0     2.0   \n",
       "35    0.536433   0.034028   0.619512   0.492754              20.0     1.0   \n",
       "34    0.533506   0.030729   0.604878   0.492754              20.0     1.0   \n",
       "67    0.532265   0.032875   0.590244   0.473430              60.0     1.0   \n",
       "43    0.529007   0.033383   0.590244   0.487805              20.0     2.0   \n",
       "\n",
       "    rfi_fs__n_features_  \n",
       "42                  5.0  \n",
       "35                  6.0  \n",
       "34                  5.0  \n",
       "67                  6.0  \n",
       "43                  6.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_KNN = get_search_results(gs_pipe_KNN)\n",
    "results_KNN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:38.611909Z",
     "start_time": "2020-10-07T11:42:38.586975Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const spec = {\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-3ac1700bff9c269cd9d01c6b6a55584d\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"knn__p\", \"title\": \"p\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"knn__n_neighbors\", \"title\": \"Number of Neighbors\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"mean_score\", \"scale\": {\"zero\": false}, \"title\": \"accuracy\"}}, \"title\": \"KNN Performance Comparison with 5 Features\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-3ac1700bff9c269cd9d01c6b6a55584d\": [{\"mean_score\": 0.5380212874592514, \"std_score\": 0.03023528804788754, \"max_score\": 0.5951219512195122, \"min_score\": 0.4975609756097561, \"knn__n_neighbors\": 20.0, \"knn__p\": 2.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.5335061466556694, \"std_score\": 0.030728862431301678, \"max_score\": 0.6048780487804878, \"min_score\": 0.4927536231884058, \"knn__n_neighbors\": 20.0, \"knn__p\": 1.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.526749145752327, \"std_score\": 0.033800842932489424, \"max_score\": 0.5804878048780487, \"min_score\": 0.46859903381642515, \"knn__n_neighbors\": 40.0, \"knn__p\": 2.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.5241915085817525, \"std_score\": 0.04200443431849927, \"max_score\": 0.6048780487804878, \"min_score\": 0.4444444444444444, \"knn__n_neighbors\": 40.0, \"knn__p\": 1.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.52386630532972, \"std_score\": 0.036458624597099414, \"max_score\": 0.6, \"min_score\": 0.4492753623188406, \"knn__n_neighbors\": 60.0, \"knn__p\": 1.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.5186347747535447, \"std_score\": 0.034018309095134855, \"max_score\": 0.5748792270531401, \"min_score\": 0.45893719806763283, \"knn__n_neighbors\": 10.0, \"knn__p\": 1.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.5157550763913437, \"std_score\": 0.029123127807368112, \"max_score\": 0.5804878048780487, \"min_score\": 0.4830917874396135, \"knn__n_neighbors\": 60.0, \"knn__p\": 2.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.5154078787164683, \"std_score\": 0.03720050774208566, \"max_score\": 0.5804878048780487, \"min_score\": 0.4492753623188406, \"knn__n_neighbors\": 10.0, \"knn__p\": 2.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.5051301991280783, \"std_score\": 0.034594590408508714, \"max_score\": 0.5609756097560976, \"min_score\": 0.43478260869565216, \"knn__n_neighbors\": 100.0, \"knn__p\": 1.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.5009088409724678, \"std_score\": 0.032470106205716755, \"max_score\": 0.5707317073170731, \"min_score\": 0.43478260869565216, \"knn__n_neighbors\": 100.0, \"knn__p\": 2.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.45946506421585964, \"std_score\": 0.03282227093534724, \"max_score\": 0.5317073170731708, \"min_score\": 0.4106280193236715, \"knn__n_neighbors\": 1.0, \"knn__p\": 2.0, \"rfi_fs__n_features_\": 5.0}, {\"mean_score\": 0.45817053532854174, \"std_score\": 0.03032305688635816, \"max_score\": 0.5219512195121951, \"min_score\": 0.4106280193236715, \"knn__n_neighbors\": 1.0, \"knn__p\": 1.0, \"rfi_fs__n_features_\": 5.0}]}};\n",
       "const opt = {};\n",
       "const type = \"vega-lite\";\n",
       "const id = \"2eee1bcb-0726-4f87-b4b2-9d999ce3350a\";\n",
       "\n",
       "const output_area = this;\n",
       "\n",
       "require([\"nbextensions/jupyter-vega/index\"], function(vega) {\n",
       "  const target = document.createElement(\"div\");\n",
       "  target.id = id;\n",
       "  target.className = \"vega-embed\";\n",
       "\n",
       "  const style = document.createElement(\"style\");\n",
       "  style.textContent = [\n",
       "    \".vega-embed .error p {\",\n",
       "    \"  color: firebrick;\",\n",
       "    \"  font-size: 14px;\",\n",
       "    \"}\",\n",
       "  ].join(\"\\\\n\");\n",
       "\n",
       "  // element is a jQuery wrapped DOM element inside the output area\n",
       "  // see http://ipython.readthedocs.io/en/stable/api/generated/\\\n",
       "  // IPython.display.html#IPython.display.Javascript.__init__\n",
       "  element[0].appendChild(target);\n",
       "  element[0].appendChild(style);\n",
       "\n",
       "  vega.render(\"#\" + id, spec, type, opt, output_area);\n",
       "}, function (err) {\n",
       "  if (err.requireType !== \"scripterror\") {\n",
       "    throw(err);\n",
       "  }\n",
       "});\n"
      ],
      "text/plain": [
       "<vega.vegalite.VegaLite at 0x122941e4f48>"
      ]
     },
     "metadata": {
      "jupyter-vega": "#2eee1bcb-0726-4f87-b4b2-9d999ce3350a"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_KNN_5_features = results_KNN[results_KNN['rfi_fs__n_features_'] == 5.0]\n",
    "\n",
    "alt.Chart(results_KNN_5_features, \n",
    "          title='KNN Performance Comparison with 5 Features'\n",
    "         ).mark_line(point=True).encode(\n",
    "    alt.X('knn__n_neighbors', title='Number of Neighbors'),\n",
    "    alt.Y('mean_score', title='accuracy', scale=alt.Scale(zero=False)),\n",
    "    alt.Color('knn__p:N', title='p')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Gaussian) Naive Bayes (NB)\n",
    "\n",
    "A dictionary for the hyperparameters of the NB classifier is defined as below:\n",
    "\n",
    "* var_smoothing: start with 10 and end with $10^{-2}$ with 10 different values for random search over only 20 different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:38.647781Z",
     "start_time": "2020-10-07T11:42:38.613871Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "D_train_transformed = PowerTransformer().fit_transform(D_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:50.494102Z",
     "start_time": "2020-10-07T11:42:38.649775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 20 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-2)]: Done 186 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:   11.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "pipe_NB = Pipeline([('rfi_fs', RFIFeatureSelector()), \n",
    "                     ('nb', GaussianNB())])\n",
    "\n",
    "params_pipe_NB = {'rfi_fs__n_features_': [3,4,5,6,7,8,9, Data.shape[1]],\n",
    "                  'nb__var_smoothing': np.logspace(0,-2, num=10)}\n",
    "\n",
    "n_iter_search = 20\n",
    "gs_pipe_NB = RandomizedSearchCV(estimator=pipe_NB, \n",
    "                          param_distributions=params_pipe_NB, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='accuracy',\n",
    "                          n_iter=n_iter_search,\n",
    "                          verbose=1) \n",
    "\n",
    "gs_pipe_NB.fit(D_train_transformed, t_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:50.502081Z",
     "start_time": "2020-10-07T11:42:50.496097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfi_fs__n_features_': 5, 'nb__var_smoothing': 0.02782559402207126}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_NB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:50.512088Z",
     "start_time": "2020-10-07T11:42:50.505073Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.533462657613967"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_NB.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, NB model has a mean accuracy score of 0.534. The best parameters for the NB model are 5 features with 0.077 var_smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the NB model accuracy based on other parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:50.543996Z",
     "start_time": "2020-10-07T11:42:50.514049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>rfi_fs__n_features_</th>\n",
       "      <th>nb__var_smoothing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.533563</td>\n",
       "      <td>0.030686</td>\n",
       "      <td>0.595122</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.027826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.530980</td>\n",
       "      <td>0.030128</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.129155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.527428</td>\n",
       "      <td>0.036078</td>\n",
       "      <td>0.604878</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.129155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.526136</td>\n",
       "      <td>0.036219</td>\n",
       "      <td>0.604878</td>\n",
       "      <td>0.468599</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.046416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.526136</td>\n",
       "      <td>0.036219</td>\n",
       "      <td>0.604878</td>\n",
       "      <td>0.468599</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.046416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_score  std_score  max_score  min_score  rfi_fs__n_features_  \\\n",
       "16    0.533563   0.030686   0.595122   0.473430                  5.0   \n",
       "7     0.530980   0.030128   0.585366   0.478261                  5.0   \n",
       "19    0.527428   0.036078   0.604878   0.473430                  9.0   \n",
       "11    0.526136   0.036219   0.604878   0.468599                  9.0   \n",
       "15    0.526136   0.036219   0.604878   0.468599                  9.0   \n",
       "\n",
       "    nb__var_smoothing  \n",
       "16           0.027826  \n",
       "7            0.129155  \n",
       "19           0.129155  \n",
       "11           0.046416  \n",
       "15           0.046416  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_NB = get_search_results(gs_pipe_NB)\n",
    "results_NB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:42:50.571895Z",
     "start_time": "2020-10-07T11:42:50.545964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const spec = {\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-4d3117f305b4fbfcf70c8c3820997a3a\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"nb__var_smoothing\", \"title\": \"Var. Smoothing\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"mean_score\", \"scale\": {\"zero\": false}, \"title\": \"accuracy\"}}, \"title\": \"NB Performance Comparison with 5 Features\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-4d3117f305b4fbfcf70c8c3820997a3a\": [{\"mean_score\": 0.5335627037429794, \"std_score\": 0.03068597160715191, \"max_score\": 0.5951219512195122, \"min_score\": 0.47342995169082125, \"rfi_fs__n_features_\": 5.0, \"nb__var_smoothing\": 0.02782559402207126}, {\"mean_score\": 0.5309799300891559, \"std_score\": 0.030128302683811167, \"max_score\": 0.5853658536585366, \"min_score\": 0.4782608695652174, \"rfi_fs__n_features_\": 5.0, \"nb__var_smoothing\": 0.1291549665014884}]}};\n",
       "const opt = {};\n",
       "const type = \"vega-lite\";\n",
       "const id = \"38f31467-36c7-4362-8148-ff153fa8c465\";\n",
       "\n",
       "const output_area = this;\n",
       "\n",
       "require([\"nbextensions/jupyter-vega/index\"], function(vega) {\n",
       "  const target = document.createElement(\"div\");\n",
       "  target.id = id;\n",
       "  target.className = \"vega-embed\";\n",
       "\n",
       "  const style = document.createElement(\"style\");\n",
       "  style.textContent = [\n",
       "    \".vega-embed .error p {\",\n",
       "    \"  color: firebrick;\",\n",
       "    \"  font-size: 14px;\",\n",
       "    \"}\",\n",
       "  ].join(\"\\\\n\");\n",
       "\n",
       "  // element is a jQuery wrapped DOM element inside the output area\n",
       "  // see http://ipython.readthedocs.io/en/stable/api/generated/\\\n",
       "  // IPython.display.html#IPython.display.Javascript.__init__\n",
       "  element[0].appendChild(target);\n",
       "  element[0].appendChild(style);\n",
       "\n",
       "  vega.render(\"#\" + id, spec, type, opt, output_area);\n",
       "}, function (err) {\n",
       "  if (err.requireType !== \"scripterror\") {\n",
       "    throw(err);\n",
       "  }\n",
       "});\n"
      ],
      "text/plain": [
       "<vega.vegalite.VegaLite at 0x12292b6d048>"
      ]
     },
     "metadata": {
      "jupyter-vega": "#38f31467-36c7-4362-8148-ff153fa8c465"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_NB_5_features = results_NB[results_NB['rfi_fs__n_features_'] == 5.0]\n",
    "\n",
    "alt.Chart(results_NB_5_features, \n",
    "          title='NB Performance Comparison with 5 Features'\n",
    "         ).mark_line(point=True).encode(\n",
    "    alt.X('nb__var_smoothing', title='Var. Smoothing'),\n",
    "    alt.Y('mean_score', title='accuracy', scale=alt.Scale(zero=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees (DT)\n",
    "\n",
    "A dictionary for the hyperparameters of the DT classifier is defined as below:\n",
    "\n",
    "* Value range for maximum depth (max_depth): 3, 4, 5, 6, 7\n",
    "* Value for minimum sample split (min_samples_split): 2, 3, 4, 5, 6 , 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:16.392948Z",
     "start_time": "2020-10-07T11:42:50.573889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 240 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-2)]: Done 186 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-2)]: Done 436 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-2)]: Done 786 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-2)]: Done 1236 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-2)]: Done 1786 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-2)]: Done 2436 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-2)]: Done 3186 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-2)]: Done 3600 out of 3600 | elapsed:  2.4min finished\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_DT = Pipeline([('rfi_fs', RFIFeatureSelector()),\n",
    "                    ('dt', DecisionTreeClassifier(criterion='gini'))])\n",
    "\n",
    "params_pipe_DT = {'rfi_fs__n_features_': [3,4,5,6,7,8,9, Data.shape[1]],\n",
    "                  'dt__max_depth': [3, 4, 5, 6, 7],\n",
    "                  'dt__min_samples_split': [2, 3, 4, 5, 6, 7]}\n",
    "\n",
    "gs_pipe_DT = GridSearchCV(estimator=pipe_DT, \n",
    "                          param_grid=params_pipe_DT, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='accuracy',\n",
    "                          verbose=1) \n",
    "\n",
    "gs_pipe_DT.fit(D_train, t_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:16.401924Z",
     "start_time": "2020-10-07T11:45:16.395941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__max_depth': 5, 'dt__min_samples_split': 3, 'rfi_fs__n_features_': 6}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_DT.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:16.411897Z",
     "start_time": "2020-10-07T11:45:16.405916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5638538635628839"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe_DT.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above , DT model has a mean accuracy score of 0.564. The best parameters for the DT model are  6 features with maximum depth of 5 and minimum split value of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the DT model accuracy based on other parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:16.561534Z",
     "start_time": "2020-10-07T11:45:16.413891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const spec = {\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-41968c42fa55e0ad6011f5b1bfff9477\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"dt__max_depth\", \"title\": \"Max Depth\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"dt__min_samples_split\", \"title\": \"Min Samples for Split\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"mean_score\", \"scale\": {\"zero\": false}, \"title\": \"accuracy\"}}, \"title\": \"DT Performance Comparison with 6 Features\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-41968c42fa55e0ad6011f5b1bfff9477\": [{\"mean_score\": 0.5639181493264207, \"std_score\": 0.0317698700506156, \"max_score\": 0.6146341463414634, \"min_score\": 0.5072463768115942, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 3.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5639181493264207, \"std_score\": 0.0317698700506156, \"max_score\": 0.6146341463414634, \"min_score\": 0.5072463768115942, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5635929460743881, \"std_score\": 0.0313713987286841, \"max_score\": 0.6146341463414634, \"min_score\": 0.5072463768115942, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 4.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5635929460743881, \"std_score\": 0.0313713987286841, \"max_score\": 0.6146341463414634, \"min_score\": 0.5072463768115942, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 6.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5635929460743881, \"std_score\": 0.0313713987286841, \"max_score\": 0.6146341463414634, \"min_score\": 0.5072463768115942, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 7.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5626204783786968, \"std_score\": 0.03090569435753309, \"max_score\": 0.6097560975609756, \"min_score\": 0.5072463768115942, \"dt__max_depth\": 5.0, \"dt__min_samples_split\": 2.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5574894937355169, \"std_score\": 0.03560416685404393, \"max_score\": 0.624390243902439, \"min_score\": 0.48792270531400966, \"dt__max_depth\": 4.0, \"dt__min_samples_split\": 3.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5574894937355169, \"std_score\": 0.03560416685404393, \"max_score\": 0.624390243902439, \"min_score\": 0.48792270531400966, \"dt__max_depth\": 4.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5574894937355169, \"std_score\": 0.03560416685404393, \"max_score\": 0.624390243902439, \"min_score\": 0.48792270531400966, \"dt__max_depth\": 4.0, \"dt__min_samples_split\": 7.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5574894937355169, \"std_score\": 0.03560416685404393, \"max_score\": 0.624390243902439, \"min_score\": 0.48792270531400966, \"dt__max_depth\": 4.0, \"dt__min_samples_split\": 6.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5574894937355169, \"std_score\": 0.03560416685404393, \"max_score\": 0.624390243902439, \"min_score\": 0.48792270531400966, \"dt__max_depth\": 4.0, \"dt__min_samples_split\": 4.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5561918227877932, \"std_score\": 0.03495461460505111, \"max_score\": 0.6195121951219512, \"min_score\": 0.48792270531400966, \"dt__max_depth\": 4.0, \"dt__min_samples_split\": 2.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5494191115824201, \"std_score\": 0.03706340892705418, \"max_score\": 0.6146341463414634, \"min_score\": 0.47342995169082125, \"dt__max_depth\": 6.0, \"dt__min_samples_split\": 6.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5478025215034759, \"std_score\": 0.03676750526083422, \"max_score\": 0.6146341463414634, \"min_score\": 0.47342995169082125, \"dt__max_depth\": 6.0, \"dt__min_samples_split\": 7.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5474867444326618, \"std_score\": 0.037818811139768926, \"max_score\": 0.6146341463414634, \"min_score\": 0.47342995169082125, \"dt__max_depth\": 6.0, \"dt__min_samples_split\": 3.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5474867444326618, \"std_score\": 0.03711284866913453, \"max_score\": 0.6146341463414634, \"min_score\": 0.47342995169082125, \"dt__max_depth\": 6.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5471521149994109, \"std_score\": 0.035867198396882974, \"max_score\": 0.6097560975609756, \"min_score\": 0.47342995169082125, \"dt__max_depth\": 6.0, \"dt__min_samples_split\": 2.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5465142767369702, \"std_score\": 0.037064512544029836, \"max_score\": 0.6146341463414634, \"min_score\": 0.47342995169082125, \"dt__max_depth\": 6.0, \"dt__min_samples_split\": 4.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5426086956521737, \"std_score\": 0.035555463925892226, \"max_score\": 0.6097560975609756, \"min_score\": 0.46859903381642515, \"dt__max_depth\": 7.0, \"dt__min_samples_split\": 6.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5419582891481087, \"std_score\": 0.03357082973450966, \"max_score\": 0.6048780487804878, \"min_score\": 0.47342995169082125, \"dt__max_depth\": 7.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5413047405836375, \"std_score\": 0.03490109360921463, \"max_score\": 0.6048780487804878, \"min_score\": 0.46859903381642515, \"dt__max_depth\": 7.0, \"dt__min_samples_split\": 7.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5400196378775382, \"std_score\": 0.03522466562597499, \"max_score\": 0.6048780487804878, \"min_score\": 0.463768115942029, \"dt__max_depth\": 7.0, \"dt__min_samples_split\": 2.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5396944346255056, \"std_score\": 0.03582312193507738, \"max_score\": 0.6048780487804878, \"min_score\": 0.463768115942029, \"dt__max_depth\": 7.0, \"dt__min_samples_split\": 4.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5383904795569694, \"std_score\": 0.03621930129311339, \"max_score\": 0.6097560975609756, \"min_score\": 0.463768115942029, \"dt__max_depth\": 7.0, \"dt__min_samples_split\": 3.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5209520443030516, \"std_score\": 0.0374889250779176, \"max_score\": 0.5756097560975609, \"min_score\": 0.43478260869565216, \"dt__max_depth\": 3.0, \"dt__min_samples_split\": 3.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5209520443030516, \"std_score\": 0.0374889250779176, \"max_score\": 0.5756097560975609, \"min_score\": 0.43478260869565216, \"dt__max_depth\": 3.0, \"dt__min_samples_split\": 7.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5209520443030516, \"std_score\": 0.0374889250779176, \"max_score\": 0.5756097560975609, \"min_score\": 0.43478260869565216, \"dt__max_depth\": 3.0, \"dt__min_samples_split\": 4.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5209520443030516, \"std_score\": 0.0374889250779176, \"max_score\": 0.5756097560975609, \"min_score\": 0.43478260869565216, \"dt__max_depth\": 3.0, \"dt__min_samples_split\": 6.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5209520443030516, \"std_score\": 0.0374889250779176, \"max_score\": 0.5756097560975609, \"min_score\": 0.43478260869565216, \"dt__max_depth\": 3.0, \"dt__min_samples_split\": 5.0, \"rfi_fs__n_features_\": 6.0}, {\"mean_score\": 0.5196543733553277, \"std_score\": 0.03713295595497576, \"max_score\": 0.5707317073170731, \"min_score\": 0.43478260869565216, \"dt__max_depth\": 3.0, \"dt__min_samples_split\": 2.0, \"rfi_fs__n_features_\": 6.0}]}};\n",
       "const opt = {};\n",
       "const type = \"vega-lite\";\n",
       "const id = \"53f04a10-ecc4-4c6a-ad6d-6255a70b67c1\";\n",
       "\n",
       "const output_area = this;\n",
       "\n",
       "require([\"nbextensions/jupyter-vega/index\"], function(vega) {\n",
       "  const target = document.createElement(\"div\");\n",
       "  target.id = id;\n",
       "  target.className = \"vega-embed\";\n",
       "\n",
       "  const style = document.createElement(\"style\");\n",
       "  style.textContent = [\n",
       "    \".vega-embed .error p {\",\n",
       "    \"  color: firebrick;\",\n",
       "    \"  font-size: 14px;\",\n",
       "    \"}\",\n",
       "  ].join(\"\\\\n\");\n",
       "\n",
       "  // element is a jQuery wrapped DOM element inside the output area\n",
       "  // see http://ipython.readthedocs.io/en/stable/api/generated/\\\n",
       "  // IPython.display.html#IPython.display.Javascript.__init__\n",
       "  element[0].appendChild(target);\n",
       "  element[0].appendChild(style);\n",
       "\n",
       "  vega.render(\"#\" + id, spec, type, opt, output_area);\n",
       "}, function (err) {\n",
       "  if (err.requireType !== \"scripterror\") {\n",
       "    throw(err);\n",
       "  }\n",
       "});\n"
      ],
      "text/plain": [
       "<vega.vegalite.VegaLite at 0x12282a31bc8>"
      ]
     },
     "metadata": {
      "jupyter-vega": "#53f04a10-ecc4-4c6a-ad6d-6255a70b67c1"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_DT = get_search_results(gs_pipe_DT)\n",
    "\n",
    "results_DT_6_features = results_DT[results_DT['rfi_fs__n_features_'] == 6.0]\n",
    "\n",
    "alt.Chart(results_DT_6_features, \n",
    "          title='DT Performance Comparison with 6 Features'\n",
    "         ).mark_line(point=True).encode(\n",
    "    alt.X('dt__min_samples_split', title='Min Samples for Split'),\n",
    "    alt.Y('mean_score', title='accuracy', scale=alt.Scale(zero=False)),\n",
    "    alt.Color('dt__max_depth:N', title='Max Depth')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean accuracy scores for each classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:16.569476Z",
     "start_time": "2020-10-07T11:45:16.563495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score for KNN model:  0.5379890074361461\n",
      "Mean accuracy score for NB model:  0.533462657613967\n",
      "Mean accuracy score for DT model:  0.5638538635628839\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy score for KNN model: \" ,gs_pipe_KNN.best_score_)\n",
    "print(\"Mean accuracy score for NB model: \" ,gs_pipe_NB.best_score_)\n",
    "print(\"Mean accuracy score for DT model: \" ,gs_pipe_DT.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above accuracy scores, it can be stated that the best model out of the three explored is DT model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Performance Comparison <a class=\"anchor\" id=\"5\"></a> \n",
    "\n",
    "After optimizing each of three classifiers using the training data, test data has been fitted in cross-validation manner in order to compare the performance of each model. Pairwise t-test has been conducted to determine whether the performance difference of each pair of models is statistically significant. This is done because cross-validation is a random process. \n",
    "\n",
    "Paired t-test has been performed for the below model pairs with accuracy score.\n",
    "\n",
    "* DT vs. KNN\n",
    "* DT vs. NB\n",
    "* KNN vs. NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:17.114021Z",
     "start_time": "2020-10-07T11:45:16.573470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46398526136999596"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Stratified 5-fold cross-validation with 3 repetitions \n",
    "cv_results_KNN = cross_val_score(estimator=gs_pipe_KNN.best_estimator_,\n",
    "                                 X=D_test,\n",
    "                                 y=t_test, \n",
    "                                 cv=cv_method, \n",
    "                                 n_jobs=-2,\n",
    "                                 scoring='accuracy')\n",
    "cv_results_KNN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:17.665546Z",
     "start_time": "2020-10-07T11:45:17.117013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47868289637952555"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_test_transformed = PowerTransformer().fit_transform(D_test)\n",
    "\n",
    "cv_results_NB = cross_val_score(estimator=gs_pipe_NB.best_estimator_,\n",
    "                                X=D_test_transformed,\n",
    "                                y=t_test, \n",
    "                                cv=cv_method, \n",
    "                                n_jobs=-2,\n",
    "                                scoring='accuracy')\n",
    "cv_results_NB.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:18.218067Z",
     "start_time": "2020-10-07T11:45:17.667542Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.524839933625288"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_DT = cross_val_score(estimator=gs_pipe_DT.best_estimator_,\n",
    "                                X=D_test,\n",
    "                                y=t_test, \n",
    "                                cv=cv_method, \n",
    "                                n_jobs=-2,\n",
    "                                scoring='accuracy')\n",
    "cv_results_DT.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `stats.ttest_rel` function from the `SciPy` module has been used to run the t-tests on **test data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:18.239013Z",
     "start_time": "2020-10-07T11:45:18.221061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=3.253165337244752, pvalue=0.0057762135321397425)\n",
      "Ttest_relResult(statistic=2.9854080415200275, pvalue=0.00983174519898834)\n",
      "Ttest_relResult(statistic=-0.8391130103058895, pvalue=0.4155046533053566)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.ttest_rel(cv_results_DT, cv_results_KNN))\n",
    "print(stats.ttest_rel(cv_results_DT, cv_results_NB))\n",
    "print(stats.ttest_rel(cv_results_KNN, cv_results_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the results above, DT is statistically the best classifier model at 95% significance level. This conclusion has been taken due the fact that $p$-value is smaller than 0.05, which in other words says there is a statistically significant difference between model pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation using other methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, Recall, F1 Score & Confusion Matrix can also used to evaluate the model as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:18.274915Z",
     "start_time": "2020-10-07T11:45:18.241007Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_KNN = gs_pipe_KNN.predict(D_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:18.281930Z",
     "start_time": "2020-10-07T11:45:18.276938Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_NB = gs_pipe_NB.predict(D_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:18.291871Z",
     "start_time": "2020-10-07T11:45:18.285893Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_DT = gs_pipe_DT.predict(D_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:18.314845Z",
     "start_time": "2020-10-07T11:45:18.293867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report for K-Nearest Neighbor\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.36      0.36       100\n",
      "           1       0.56      0.50      0.53       189\n",
      "           2       0.40      0.45      0.42       153\n",
      "\n",
      "    accuracy                           0.45       442\n",
      "   macro avg       0.44      0.44      0.44       442\n",
      "weighted avg       0.46      0.45      0.45       442\n",
      "\n",
      "\n",
      "Classification report for Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.50      0.43       100\n",
      "           1       0.59      0.58      0.58       189\n",
      "           2       0.46      0.37      0.41       153\n",
      "\n",
      "    accuracy                           0.49       442\n",
      "   macro avg       0.47      0.48      0.47       442\n",
      "weighted avg       0.49      0.49      0.49       442\n",
      "\n",
      "\n",
      "Classification report for Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.47      0.44       100\n",
      "           1       0.71      0.58      0.64       189\n",
      "           2       0.45      0.51      0.48       153\n",
      "\n",
      "    accuracy                           0.53       442\n",
      "   macro avg       0.52      0.52      0.52       442\n",
      "weighted avg       0.55      0.53      0.54       442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"\\nClassification report for K-Nearest Neighbor\") \n",
    "print(metrics.classification_report(t_test, pred_KNN))\n",
    "print(\"\\nClassification report for Naive Bayes\") \n",
    "print(metrics.classification_report(t_test, pred_NB))\n",
    "print(\"\\nClassification report for Decision Tree\") \n",
    "print(metrics.classification_report(t_test, pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:45:18.333760Z",
     "start_time": "2020-10-07T11:45:18.316839Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for K-Nearest Neighbor\n",
      "[[36 25 39]\n",
      " [31 94 64]\n",
      " [35 49 69]]\n",
      "\n",
      "Confusion matrix for Naive Bayes\n",
      "[[ 50  21  29]\n",
      " [ 41 110  38]\n",
      " [ 40  57  56]]\n",
      "\n",
      "Confusion matrix for Decision Tree\n",
      "[[ 47  14  39]\n",
      " [ 22 110  57]\n",
      " [ 43  32  78]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion matrix for K-Nearest Neighbor\") \n",
    "print(metrics.confusion_matrix(t_test, pred_KNN))\n",
    "print(\"\\nConfusion matrix for Naive Bayes\") \n",
    "print(metrics.confusion_matrix(t_test, pred_NB))\n",
    "print(\"\\nConfusion matrix for Decision Tree\") \n",
    "print(metrics.confusion_matrix(t_test, pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on which organization uses the model, the \"precision\" or the \"recall\" may become key performance indicator. For an example, if government organization that runs a program to find number of womens who do not use any contraceptive method, \"recall\" would be the best performance indicator. According to above classification report, its is evident that DT is the best method with higher recall value.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Limitations <a class=\"anchor\" id=\"6\"></a> \n",
    "\n",
    "Since the size of the data set is significantly small (only 1473), the accuracy rate of the models developed could be considerably low to represent entire county (Indonesia). Also, this data-set could be a biased one, considering the small size of it. As a well know limitation of the supervised machine learning is that it requires large number of data to achieve a reasonably accurate model. Therefore, if a larger data set is available for this exercise, then more accurate model could have been developed. In oppose to the supervised machine learning, deep learning would have been a better approach for this kind of problems with limited data-sets.\n",
    "\n",
    "There is a room to improve the model in future by considering more parameters and more ensemble methods during the hyperparameter tuning process. \n",
    "\n",
    "There are few assumptions for the paired sample t-test and it can impact to the evaluation. Main assumptions in paired sample t-test are;\n",
    "* The data-set is normally distributed and has no outliers\n",
    "* Variable in the data-set is independent and continuous\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Summary  <a class=\"anchor\" id=\"7\"></a> \n",
    "\n",
    "Contraceptive method data-set is a multi-class classification problem and K-Nearest Neighbors (KNN), Naive Bayes (NB) & Decision trees (DT) classifiers have been examined for this classification problem. \n",
    "\n",
    "When evaluating the training set, the DT model with 6 of the best features selected by Random Forest Importance (RFI) produces the highest cross-validated accuracy score. Similarly, when evaluating the test set, the DT model performed the best on accuracy score of approximately 55%. Therefore, it can be concluded that the DT method is the most suitable model for this classification problem based on the given data-set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* Dua, D. and Graff, C (2019). UCI Machine Learning Repository: Contraceptive Method Choice Data Set [online]. Available at\n",
    "https://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice [Accessed 2019-06-02]\n",
    "* Aksakalli V, Yenice Z (2019). Feature Ranking [online].  Available at https://www.featureranking.com/\n",
    "* Aksakalli V (2019). Machine Learning (1910) Lecture Notes, RMIT University, Melbourne, delivered Semester-1 2019.\n",
    "* Jones E, Oliphant E, Peterson P, et al. SciPy: Open Source Scientific Tools for Python, 2001-, http://www.scipy.org/ [Accessed 2019-05-26].\n",
    "* Pedregosa et al. (2011). Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-\n",
    "2830.\n",
    "* Travis E, Oliphant (2006). A guide to NumPy, USA: Trelgol Publishing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
